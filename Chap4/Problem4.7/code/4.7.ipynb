{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4.7 \n",
    "# Implemetation of Non-recursive Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(target):\n",
    "    \"\"\"\n",
    "    This function computes the entropy, which has one input:\n",
    "    1. target: the df column of response\n",
    "    \"\"\"\n",
    "    ent = 0\n",
    "    \n",
    "    for element in pd.value_counts(target):\n",
    "        p = element / len(target)\n",
    "        ent += -p * np.log2(p)\n",
    "    \n",
    "    return ent  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Information GainÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def information_gain(target_name, attribute_name, data):\n",
    "    \"\"\"\n",
    "    This function computes the information gain of an attribute, which has three inputs:\n",
    "    1. target_name: string, the column name of response\n",
    "    2. attribute_name: string, the column name of the attribute\n",
    "    3. data: dataframe\n",
    "    \n",
    "    The class of the attribute could be numberic or object \n",
    "    \"\"\"\n",
    "    ent = entropy(data[target_name])\n",
    "    df_slice = data[[target_name, attribute_name]]\n",
    "    \n",
    "    node_info = [] # store the best split information\n",
    "    \n",
    "    # information gain for categorical attributes\n",
    "    if not np.issubdtype(data[attribute_name].dtype, np.number):\n",
    "        new_ent = 0\n",
    "        for attr in pd.value_counts(data[attribute_name]).index:\n",
    "            dv = df_slice[df_slice[attribute_name] == attr] # the subset of specific attribute value\n",
    "            \n",
    "            ent_dv = entropy(dv[target_name]) # the entropy of the subset\n",
    "            new_ent += len(dv)/len(data) * ent_dv # compute the sum of entropy \n",
    "            node_info.append(attr)\n",
    "            \n",
    "    # information gain for numerical attributes\n",
    "    if np.issubdtype(data[attribute_name].dtype, np.number): \n",
    "        new_ent = np.inf\n",
    "        sorted_attr = sorted(data[attribute_name].values)\n",
    "        points  = [(sorted_attr[i]+sorted_attr[i+1])/2 for i in range(len(sorted_attr)-1)]\n",
    "        for point in points:\n",
    "            # compute the entropy for two subsets, + and -\n",
    "            dv1 = df_slice[df_slice[attribute_name] < point]\n",
    "            ent_dv1 = len(dv1)/len(data) * entropy(dv1[target_name])\n",
    "            \n",
    "            dv2 = df_slice[df_slice[attribute_name] > point]\n",
    "            ent_dv2 = len(dv2)/len(data) * entropy(dv2[target_name])\n",
    "            \n",
    "            # find the smallest entropy sum\n",
    "            if ent_dv1+ent_dv2 < new_ent:\n",
    "                new_ent = ent_dv1 + ent_dv2\n",
    "                node_info = [point]\n",
    "\n",
    "        \n",
    "    return ent - new_ent, node_info\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_split(data, target_name):\n",
    "    \"\"\"\n",
    "    This function returns the best split information (tree stump) of certain dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    attributes = list(data.columns) # get all the attributes\n",
    "    attributes.remove(target_name)\n",
    "    origin_gain = 0\n",
    "    \n",
    "    for attr in attributes:\n",
    "        gain, node_info = information_gain(target_name, attr, data)\n",
    "        if gain > origin_gain:\n",
    "            origin_gain = gain\n",
    "            node_column_name = attr\n",
    "            split_info = node_info\n",
    "    return node_column_name, split_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majorClass(data, target_name):\n",
    "    \"\"\"\n",
    "    Majority Function simply tells which class has more entries in given data-set\n",
    "    \"\"\"\n",
    "    value_cnt = pd.value_counts(data[target_name])\n",
    "    # np.unique(data['quality'])[np.argmax(np.unique(data['quality'],return_counts=True)[1])]\n",
    "    major = list(value_cnt.index[value_cnt.values == value_cnt.max()])\n",
    "\n",
    "    return major[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_data(data, best_attr_name, value, isnumber = True, islarger = None):\n",
    "    \"\"\"\n",
    "    This function return the new dataframe based on the best split information.\n",
    "    It has five inputs:\n",
    "    1. data: the dataframe that should be sliced\n",
    "    2. best_attr_name: string, the name of the attribute which is going to be splitted on\n",
    "    3. value: list, the best split values\n",
    "    4. isnumber: boolean, identify if the best split value is numeric\n",
    "    5. islarger: boolean, identify if the condition of splitting is \n",
    "                 'larger than the best split value'\n",
    "    \"\"\"\n",
    "    \n",
    "    if isnumber:\n",
    "        if islarger:\n",
    "            new_df = data[data[best_attr_name] > value]\n",
    "        else: new_df = data[data[best_attr_name] < value]\n",
    "    else: new_df = data[data[best_attr_name] == value]\n",
    "    return new_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_data_dict(data, best_attr_name, best_split_info):\n",
    "    \"\"\"\n",
    "    return the list of all sub-datas based on a column\n",
    "    \"\"\"\n",
    "    sub_data_dict = {}\n",
    "    \n",
    "    if isinstance(best_split_info[0], numbers.Number):\n",
    "        values = ['<'+str(best_split_info[0]), '>'+str(best_split_info[0])]\n",
    "        islargers = [False, True]\n",
    "        for i in range(2):\n",
    "            value = values[i]\n",
    "            sub_data = partition_data(data, best_attr_name, best_split_info[0], True, islargers[i])\n",
    "            sub_data_dict[value] = sub_data\n",
    "                \n",
    "                \n",
    "    else:\n",
    "        for value in best_split_info:\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
    "            sub_data = partition_data(data, best_attr_name, value, False)\n",
    "            sub_data_dict[value] = sub_data\n",
    "    return sub_data_dict   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_recursive_tree(data,max_depth, target_name='quality'):\n",
    "    \"\"\"\n",
    "    This function builds a decision tree with stack instead of a recursive loop.\n",
    "    There are three inputs:\n",
    "    1. data: the df of the train data\n",
    "    2. max_depth: the max_depth of decision tree\n",
    "    3. target_name: string, the column name of the response\n",
    "    \"\"\"\n",
    "    \n",
    "    init_col, init_split = best_split(data, target_name)\n",
    "    \n",
    "    root = {init_col:{}}\n",
    "    data_stack = []\n",
    "    data_stack.append(data)\n",
    "    \n",
    "    col_stack = []\n",
    "    col_stack.append(init_col)\n",
    "    \n",
    "    split_info_stack = []\n",
    "    split_info_stack.append(init_split)\n",
    "    \n",
    "    node_stack = []\n",
    "    node_stack.append(root[init_col])\n",
    "    \n",
    " \n",
    "    level_dict = {init_col:1}\n",
    "    \n",
    "    \n",
    "    while (len(data_stack) > 0):\n",
    "       \n",
    "        data_partition = data_stack.pop()\n",
    "        col = col_stack.pop()\n",
    "        best_split_info = split_info_stack.pop()\n",
    "        current_point = node_stack.pop()\n",
    "        \n",
    "        if level_dict[col] > max_depth:\n",
    "            current_point = majorClass(data_partition, target_name)\n",
    "            \n",
    "        else:\n",
    "            part_data_dict = sub_data_dict(data_partition, col, best_split_info)\n",
    "        \n",
    "            for key in part_data_dict:\n",
    "                level_dict[key] = level_dict[col]+0.1\n",
    "\n",
    "            for key in part_data_dict:\n",
    "\n",
    "                sub_data = part_data_dict[key]\n",
    "\n",
    "                if len(pd.value_counts(sub_data[target_name])) == 1:\n",
    "\n",
    "                    end_label = majorClass(sub_data,target_name)\n",
    "                    label = col\n",
    "\n",
    "                    if label in current_point.keys():\n",
    "                        current_point[label][key] = end_label\n",
    "\n",
    "                    else: \n",
    "                        current_point[key] = end_label\n",
    "                    \n",
    "                    continue\n",
    "\n",
    "                elif len(pd.value_counts(sub_data[target_name])) > 1:\n",
    "                    \n",
    "                    if level_dict[key] == max_depth+0.1:\n",
    "                        current_point[key] = majorClass(sub_data, target_name)\n",
    "                        \n",
    "                    elif level_dict[key] < max_depth:\n",
    "                        col, split = best_split(sub_data, target_name)\n",
    "                        current_point[key] = {}\n",
    "                        current_point[key][col] = {}\n",
    "\n",
    "                        data_stack.append(sub_data)\n",
    "                        col_stack.append(col)\n",
    "                        node_stack.append(current_point[key])\n",
    "                        split_info_stack.append(split)\n",
    "\n",
    "                        level_dict[col] = level_dict[key]+1-0.1\n",
    "\n",
    "                    continue\n",
    "\n",
    "    return root\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_float(value):\n",
    "    \"\"\"\n",
    "    check if a string input is numeric\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = float(value)\n",
    "        return True\n",
    "    except: return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(input_df,tree,default = 'No prediction'):\n",
    "    \"\"\"\n",
    "    Prediction of a new/unseen dataframe instance. This takes two parameters:\n",
    "    1. input_df: a row of new instance with column names\n",
    "    2. tree: the built decision tree\n",
    "    3. default value: return the value in case of \n",
    "       new/unseen instance contains unseen attribute value.\n",
    "    \n",
    "    Also it is made in a recrusive manner.\n",
    "    \"\"\"\n",
    "    for column in input_df:\n",
    "        if column in list(tree.keys()):\n",
    "            \n",
    "            attr_value = list(input_df[column])[0]\n",
    "            \n",
    "            if isinstance(attr_value, numbers.Number):\n",
    "                threshold = float(list(tree[column].keys())[0][1:])\n",
    "                if attr_value < threshold:\n",
    "                    attr_value = '<'+str(threshold)\n",
    "                else: \n",
    "                    attr_value = '>'+str(threshold)\n",
    "                    result = tree[column][attr_value]\n",
    "            else: # do categorical classification\n",
    "                try:\n",
    "\n",
    "                    result = tree[column][attr_value] \n",
    "                except:\n",
    "                    return default\n",
    "  \n",
    "            result = tree[column][attr_value]\n",
    "\n",
    "            if isinstance(result,dict):\n",
    "                return predict(input_df,result)\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train the Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.txt', sep=',')\n",
    "data = data.drop(['Id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>root</th>\n",
       "      <th>sound</th>\n",
       "      <th>stripes</th>\n",
       "      <th>umbilical</th>\n",
       "      <th>touch</th>\n",
       "      <th>density</th>\n",
       "      <th>sugar</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dark-green</td>\n",
       "      <td>roll-up</td>\n",
       "      <td>dull</td>\n",
       "      <td>clear</td>\n",
       "      <td>hollow</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.460</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pitch-dark</td>\n",
       "      <td>roll-up</td>\n",
       "      <td>dead</td>\n",
       "      <td>clear</td>\n",
       "      <td>hollow</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.376</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pitch-dark</td>\n",
       "      <td>roll-up</td>\n",
       "      <td>dull</td>\n",
       "      <td>clear</td>\n",
       "      <td>hollow</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.264</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dark-green</td>\n",
       "      <td>roll-up</td>\n",
       "      <td>dead</td>\n",
       "      <td>clear</td>\n",
       "      <td>hollow</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.318</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>roll-up</td>\n",
       "      <td>dull</td>\n",
       "      <td>clear</td>\n",
       "      <td>hollow</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.215</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        color     root sound stripes umbilical touch  density  sugar quality\n",
       "0  dark-green  roll-up  dull   clear    hollow  hard    0.697  0.460    good\n",
       "1  pitch-dark  roll-up  dead   clear    hollow  hard    0.744  0.376    good\n",
       "2  pitch-dark  roll-up  dull   clear    hollow  hard    0.634  0.264    good\n",
       "3  dark-green  roll-up  dead   clear    hollow  hard    0.608  0.318    good\n",
       "4       white  roll-up  dull   clear    hollow  hard    0.556  0.215    good"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the train and test set\n",
    "train=data.sample(frac=0.9,random_state=4)\n",
    "\n",
    "# the test set should only contain features values\n",
    "test_x, test_y =data.drop(train.index).drop(['quality'], axis=1), data.drop(train.index)['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree\n",
    "tree0 = non_recursive_tree(train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stripes': {'blurred': 'bad',\n",
       "  'clear': {'root': {'roll-up': 'good',\n",
       "    'slighly-curled': 'good',\n",
       "    'stiff': 'bad'}},\n",
       "  'indistinct': {'touch': {'hard': 'bad', 'soft': 'good'}}}}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stripes': {'blurred': 'bad', 'clear': 'good', 'indistinct': 'bad'}}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1 = non_recursive_tree(train, 1)\n",
    "tree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "prediction_result = []\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    new_pred = predict(test_x.iloc[[i]], tree0)\n",
    "    prediction_result.append(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'good']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     good\n",
       "14     bad\n",
       "Name: quality, dtype: object"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
